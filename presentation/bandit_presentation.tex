\documentclass{beamer}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{listings}

\DeclareMathOperator*{\argmin}{arg\,min}

\usepackage{graphicx}

\usetheme{metropolis}          
\title{Bandit Problems}
\date{\today}
\author{Vishakh Gopu, Frederik Jensen}
\institute{Advanced Machine Learning - Spring 2017}
\begin{document}
\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
% Introduction
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

\section{Introduction}
\begin{frame}{Overview of papers}   
  Three main problem settings: 
  \begin{enumerate}
  \item
    Restless Bandits
    \begin{itemize}
    \item
      Bertsimas, Dimitris, Nin\~o-Mora, Jos\'e. 2000. Restless Bandits, Linear Programming
      Relaxations, and a Primal-Dual Index Heuristic. Operations Research, 48(1), 80–90.
    \end{itemize}
  \item
    Graph Structured Feedback
    \begin{itemize}
    \item
      Alon, Noga, Cesa-Bianchi, Nicol\`o, Gentile, Claudio, Mannor, Shie, Mansour, Yishay,
      Shamir, Ohad. 2014. Nonstochastic Multi-Armed Bandits with Graph-Structured Feedback.
      CoRR, abs/1409.8428.
    \end{itemize}
  \item
    Handling Variance in Rewards
    \begin{itemize}
    \item
      Hazan, Elad, Kale, Satyen. 2009. Better Algorithms for Benign Bandits. Pages 38–47 of: 
      Proceedings of the Twentieth Annual ACM-SIAM Symposium on Discrete Algorithms. SODA '09.
      Philadelphia, PA, USA: Society for Industrial and Applied Mathematics.
    \end{itemize}
  \end{enumerate}
\end{frame}

\begin{frame}{Outline}
  \begin{enumerate}

  \item Problem Definition
  
  \item
    A quick look at restless bandits
    
  \item
    Graph structured feedback and benign bandits in more depth
    \begin{itemize}
    \item
      Problem description
    \item
      Selected results
    \end{itemize}
    
  \item
    Interesting connections and relationships 
  \item
    Questions, exploration, future work
    
  \end{enumerate}
\end{frame}

\section{Problem Definition}
\begin{frame}
  \begin{enumerate}
    \item Online learner
    \item At each round $t$, picks an action from $i\in\mathcal{K}$
    \item Loss $L$ only disclosed for action $i$
    \item Regret guarantees
  \end{enumerate}
\end{frame}


\section{Restless bandits}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
% Restless bandits 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

\begin{frame}{Quick overview}
  % Talk about the problem setting and brief  high level description 
  % of the result (avoid showing any results)
  % Mention its in the interest of time
\end{frame}

\section{Non stochastic bandits with graph structured feedback}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
% Non stochastic bandits with graph structured feedback
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\begin{frame}{Problem Reformulation}
  \begin{itemize}
    % Details about the problem.
    \item Web advertisement example

    % How is it different from the general bandit
    \item Partial information setting

    \item Action set $\mathcal{K}\in \mathbb{R}^n$ for $n$ experts
    \item Feedback graph $G_t(\mathcal{K}, D_t)$ 
    \begin{enumerate}
      \item Edge $(i,j)\in D_t$ if playing $i$ at time $t$ reveals loss $j$
      \item Write $i\overline{t}{\to}j$
    \end{enumerate}
  \end{itemize}
  % setting.
  % Motivate by example of web advertisement.    
\end{frame}

\begin{frame}{High Level Overview}
  \begin{itemize}
    \item Modification of Exp3: \textit{Exp3-SET}
    
    \item Key quantity $$Q_t=\sum_{i\in |\mathcal{K}|}\frac{p_{i,t}}{q_{i,t}} = \sum_{i\in |\mathcal{K}|}\frac{p_{i,t}}{\sum_{j:j\overset{t}{\to}j} p_{j,t}}$$

    \item Regret bound satisfies $$R_T\leq \frac{\ln K}{\eta} +\frac{\eta}{2}\sum_{t=1}^T\mathbb{E}[\mas(G_t)]$$
  \end{itemize}
  % Conceptual understanding - interpolation between
  % different settings (similar to the bonus problem) - plug in and get results.
\end{frame} 

\begin{frame}{KEY RESULT 1}
  % Algorithm - similarity to Exp3. Show it
  % Key term for bound.
\end{frame}

\begin{frame}{KEY RESULT 2}
  % Getting the maximum acyclic graph in there.

\end{frame}
\section{Better algorithms for benign bandits}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
% Total variation
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\begin{frame}{High level overview}

  \begin{enumerate}
  \item
    Losses might not be truly adversarial
    \begin{itemize}   
    \item
      Example: planning a route to work in traffic
    \end{itemize}
    \item
      Can we take advantage of low variation in our algorithm?
    \item
       Can we bound regret based on variability?
      \begin{itemize}
        \item
          Learning should depend on the \textit{total variation} of the losses
        \end{itemize}
  \end{enumerate}
\end{frame}

\begin{frame}{Problem description}
  \begin{enumerate}
    \item
    Online bandit convex optimization
    \begin{itemize}
      \item
        Adversarial but oblivious
      \item
        Point ${\bf x}_t$ from $\mathcal{K}$, compact set
      \item
        Cost vector $f_{t}$
      \end{itemize}
    \item
      Take the total variation
      $Q_T=\sum_{t=1}^T \| f_t - \mu \|^2$
    \item
      Recall barrier functions and self concordant functions
      \begin{itemize}
        \item
          Ensure that we always sample from the feasible set
        \end{itemize}
     \item
       FTRL ++
        \begin{align*}
          \argmin_{{\textbf{x}}_t\in\mathcal{K}}\eta \sum_{t=1}^{t-1} \tilde{f_{\tau}}^T + \mathcal{R}(x)
        \end{align*}

    \end{enumerate}
  \end{frame}
       
\begin{frame}[fragile]{Resevoir Sampling}
  \begin{itemize}
  \item
      Sample uniformly at random from a stream of unknown size
 \end{itemize}

  \lstset{language=Python}
  \lstset{frame=lines}
  %TODO cite jeremey kun
  \lstset{basicstyle=\footnotesize}
  \begin{lstlisting}
    import random

    def reservoirSample(stream):
        for k,x in enumerate(stream, start=1):
        if random.random() < 1.0 / k:
            chosen = x

    return chosen
  \end{lstlisting}
\end{frame}

\begin{frame}{Main algorithm}
  \input{bbb_mainalgo.tex}
\end{frame}

\begin{frame}{Explore}
  \input{bbb_SIMPLEXSAMPLE}
\end{frame}
\begin{frame}{Explore-Exploit}
  \input{bbb_ELLIPSOIDSAMPLE}
\end{frame}


\begin{frame}{Bound}
  \begin{equation}
    E[Regret_t] = O(n \sqrt{\mathcal{V}Q log T} + n log^2(T) + n \mathcal{V}log(T))
  \end{equation}
\end{frame}

\section{Connections and exploration}
\begin{frame}{Connections between papers}
  \begin{enumerate}
  \item
    Letting novel mathematical tools guide the approach
  \item 
    Interpolating between problem settings
  \end{enumerate}
\end{frame}

\begin{frame}{Exploration}
  % talk about the idea we have.
\end{frame}

\section{Conclusion}
\begin{frame}{Open questions, future work}
  % Open questons from hazan, future ideas
\end{frame}

\section{Questions}
\end{document}