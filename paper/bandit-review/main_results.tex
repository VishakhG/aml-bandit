\section{Overview of main results}

\subsection{Total variation}
In this section we take a look at the main results from \citep{hazan}.
Specifically we present the main algorithms used in the paper and review 
how the authors were able to bound the regret of their algorithm in terms 
of the total variation.


\subsubsection{Algorithms}
First we state the algorithm developed in \citep{hazan} in full. The
main algorithm is composed of two prominent steps that are alternated with 
some probability. This algorithm uses resevoir sampling and the 
properties of Dikin-ellipsoids to effeciently perform online bandit linear
optimization that can then be bounded in terms of total variation.

%algorithms 
\input{bbb_mainalgo.tex}
\input{bbb_simplexsample.tex}
\input{bbb_ellipsoidsample.tex}

%descriptions
Now that we have formally stated the algorithm of \citep{hazan} and its main
components, let us step through each part of the algorithm and go into a 
bit more detail. We first examine the overall algorithm, then the 
SIMPLEXSAMPLE step and then finally the ELLIPSOIDSAMPLE step. We
give intuition when applicable and provide mathematical justification when
it adds to the conceptual understanding (as opposed to being primarily technical).

\textbf{Main Algorithm}
We start at the top level algorithm \textit{bandit online linear optimization}.\\

The algorithm has three main parts: calling SIMPLEXSAMPLE with some probability, calling ELLIPSOID-SAMPLE
with the remaining probability mass and updating the value $x_t$ at every round. At a high level the SIMPLEXSAMPLE step is an exploration step, and the ELLIPSOIDSAMPLE step is an exploration and exploitation step.\\

We see on lines 1-4 some initialization of the various quantities involved. Seen listed are the paramters of the algorithm  $\eta, \text{the exploration/exploitation trade of rate} \mathcal{V} \text{self concordant} \mathcal{R}$ and a size parameter $k$ which denotes how large of a resevoir we are willing to keep for each of our coordinates (arms). We also initialize $x$ to be the index to the minimum point in $\mathcal{R}(x)$  and the estimate for the mean reward of each hand to be zero to start.\\

We then take some action at some time step $t$ and do this for until the last timestep $T$. At each round we have the choice of exploring alone with a SIMPLEXSAMPLE or exploring and exploiting with an $ELLIPSOIDSAMPLE$. We let the proportion of time spent in either of these tasks  be determined by the parameter $\eta$ and the stage of the optimization as denoted by t. We also take into account the size of our reservoir $k$ because of how it effects the accuracy of our estimates of the mean losses being estimated. More generally we let the proportion of time we spend exploring grow smaller as time goes on (time spent in a SIMPLEXSAMPLE) and the proportion of time spent exploring and exploiting go up in 
later stages (time spent in ELLIPSOIDSAMPLE).\\

%TODO clarify what the $i_t$ step is doing 

We can see from the algorithm that our estimate of the mean $\tilde{mu}$ of each coordinate as computed using reservoir sampling only gets updated during the SIMPLEXSAMPLE procedure, but only gets used in the ELLIPSOIDSAMPLE procedure. This matches our intuition that exploiting is akin to using the information that we have collected regarding the losses of each arm and exploring involves gathering this information. We also see that $\tilde{f_t}$ is not updated when a SIMPLEXSAMPLE is taken, only when an ELLIPSOIDSAMPLE is taken. \\
%TODO clarify why the f_t is not updated in more detail


%Describe the SIMPLEXSAMPLE procedure
\textbf{SIMPLEXSAMPLE}
Now we take a look at the SIMPLEXSAMPLE procedure whose job is simply to implement reservoir sampling on all the points in the feasible set with the given reservoir size. SIMPLEXSAMPLE samples a random coordinate $i \in [n]$ uniformly, the actual sampled point  $y_t$ is the corresponding vertex $\gamma e_{i_t}$. This vertex is of the scaled n - dimensional simplex and by assumption it has to be contained inside of $\mathcal{K}$. The loss is immediately received as $f_t(i_t)$. We then do reservoir sampling: if one of the slots in our reservoir for that coordinate is empty then we put our loss in that slot, otherwise we kick one element out of the reservoir and put the new loss there. The point kicked out is done so at random uniformly. This procedure exactly implements reservoir sampling and guarantees an unbiased estimate of the mean loss for that coordinate in the limit. We return the entire vector of means to be used in the main algorithm. Every element of that vector is the estimate of the mean of the coordinate denoted by its index, at the current round t.
 
%Describe the ELLIPSOID-SAMPLE PROCEDURE
\textbf{ELLIPSOID-SAMPLE}
ELLIPSOIDSAMPLE is where we exploit our knowledge of the adversary (loss surface) by using our estimate of the mean. This is a modification of a similar procedure outlined in \citep{abernethy}. \citep{abernathy} manages to  prove that this style of sampling procedure is unbiased and has low variation with respect to the regularization which in this case are our self-concordant functions. We choose a point $y_t$ just like in SIMPLEXSAMPLE but it is  chosen from the endpoints of the principal axes of the Dikin ellipsoid $W_1(x_t)$ centered at $x_t$ this time. Recall that $x_t$ was constructed to minimize the FTRL loss $\eta \sum_{\tau=1}^T\tilde{f_t^T} +\mathcal{R}$. Since the loss minimized was in terms of our \textit{estimate} of the loss vector, this is where we are exploiting our prior knowlege of the losses associated with the coordinates. Furthermore, we update this estimate of $\tilde{f_t}$ at the end of ELLIPSOIDSAMPLE to incorporate our knowledge of the mean $\tilde{\mu_t}$ and our actually loss suffered $f_t$, which is done by adding $f_t$ to  $\eta (f_{t}^Ty_t - \tilde{\mu_{t}^T}y_t)\epsilon \lambda_{it}^{\frac{1}{2}}v_{it}$ .\\

The procedure is actually quite akin to the exploration-exploitation steps taken in FTRl or EXP3, but there is a lot of mathematical machinery needed to ensure that our sampled point $y_t$ will be in the feasible set and that our ellipsoid sampling procedure has nice properties that ensure correctness and efficiency. 

\subsubsection{Guarantees}
\input{bbb_proof.tex}


\subsection{Partial information setting}
As mentioned in the introduction, the authors in \citep{alon} set about exploring how semantic connections in the action set can influence the bandit model. In particular, they argue that similarities between actions can tighten the regret bound of the algorithm. For instance, in the case of website advertising, they hypothesise that if a user clicks on one ad for running shoes, then the user might be susceptible to click on other ads for running shoes. In contrast, if the user is not interested in one pair of running shoes, chances are that the user is not interested in running shoes at all. Thus, there exists a potential for learning something about the category of running shoes. 

The authors clervely model these semantic relationships in a \textit{feedback graph} $G_t=(\mathcal{K},D_t)$ where $\mathcal{K}$ is the set of actions and $D_t$ the set of arcs. Let any arc $(i,j)\in D_t$ for $i\not j$ if and only if playing action $i\in\mathcal{K}$ reveals the loss of action $j\in \mathcal{K}$ at time $t$. The full information setting then corresponds to a complete graph; the bandit setting, an empty graph. Furthermore, any subgraph of $G$ represents the partial information setting which is a direct interpolation between the expert and the bandit setting. In order to prove guarantees in this scenario, the authors examine some graph theoretic notions including, \textit{independence numbers}, \textit{dominating sets}, and \textit{maximum acyclic graphs}. Recall that the independence number, $\alpha(G)$, is the cardinality of the maximal subset $T\subset \mathcal{K}$ such that no two $i,j\in T$ are connected by an edge; that is $(i,j)\not\in D_t$. An independent set $T$ is maximal if no proper superset of $T$ forms an independent set. Moreover, $R\subset G$ is a dominating set if for any $j\not\in R$ there exists an $i\in R$ that exhibits a directed edge to $j$. Lastly, the maximum acyclic subgraph in $G$, denoted $\mas(G)$, is the largest subgraph in $G$ with no directed cycles. Based on these formal structures, the authors analyse and give regret bounds on modified versions of the Exp3 algorithm. 

In the uninformed setting, when the feedback graph is hidden from the learner until an action is taken, they obtain the bound

$$R_t\leq O(\sqrt{\log |\mathcal{K}|\sum_{t=1}^T\mas(G_t)}$$

whenever the feedback graph is directed. If the feedback graph is undirected, $\mas(G_t)$ is replaced by $\alpha(G)$. In the informed setting, 

$$R_t \leq O(\log K\sqrt{\log KT\sum_{t=1}^T\alpha(G_t)}$$

\subsection{LP relaxations}
